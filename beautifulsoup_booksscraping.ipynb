{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "160902bb-14e6-46cd-a8b4-8741d753e40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Title Rating    Price\n",
      "0                                       Sharp Objects   Four  Â£47.82\n",
      "1                                In a Dark, Dark Wood    One  Â£19.63\n",
      "2                                 The Past Never Ends   Four  Â£56.50\n",
      "3                                    A Murder in Time    One  Â£16.64\n",
      "4     The Murder of Roger Ackroyd (Hercule Poirot #4)   Four  Â£44.10\n",
      "5                      The Last Mile (Amos Decker #2)    Two  Â£54.21\n",
      "6              That Darkness (Gardiner and Renner #1)    One  Â£13.92\n",
      "7                Tastes Like Fear (DI Marnie Rome #3)    One  Â£10.69\n",
      "8              A Time of Torment (Charlie Parker #14)   Five  Â£48.35\n",
      "9             A Study in Scarlet (Sherlock Holmes #1)    Two  Â£16.73\n",
      "10                   Poisonous (Max Revere Novels #3)  Three  Â£26.80\n",
      "11  Murder at the 42nd Street Library (Raymond Amb...   Four  Â£54.36\n",
      "12                                        Most Wanted  Three  Â£35.28\n",
      "13                         Hide Away (Eve Duncan #20)    One  Â£11.84\n",
      "14                      Boar Island (Anna Pigeon #19)  Three  Â£59.48\n",
      "15                                          The Widow    Two  Â£27.26\n",
      "16                                  Playing with Fire  Three  Â£13.71\n",
      "17  What Happened on Beale Street (Secrets of the ...   Five  Â£25.37\n",
      "18  The Bachelor Girl's Guide to Murder (Herringfo...   Five  Â£52.30\n",
      "19   Delivering the Truth (Quaker Midwife Mystery #1)   Four  Â£20.89\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Base URL of the category (First Page)\n",
    "base_url = \"http://books.toscrape.com/catalogue/category/books/mystery_3/\"\n",
    "\n",
    "# Start with the first page\n",
    "page_url = base_url + \"index.html\"\n",
    "\n",
    "# Headers to mimic a real browser request\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Create an empty list to store book details\n",
    "book_data = []\n",
    "\n",
    "while page_url:\n",
    "    # Send a GET request to fetch the page content\n",
    "    response = requests.get(page_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Find all book containers\n",
    "        books = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "\n",
    "        # Extract book details from the current page\n",
    "        for book in books:\n",
    "            title = book.h3.a[\"title\"]\n",
    "            price = book.find(\"p\", class_=\"price_color\").text.strip()\n",
    "            rating_class = book.find(\"p\", class_=\"star-rating\")[\"class\"]\n",
    "            rating = rating_class[1]  # Second class name represents rating\n",
    "\n",
    "            # Append data to list\n",
    "            book_data.append({\"Title\": title, \"Rating\": rating, \"Price\": price})\n",
    "\n",
    "        # Find the \"Next\" button to navigate to the next page\n",
    "        next_page = soup.find(\"li\", class_=\"next\")\n",
    "        if next_page:\n",
    "            next_page_url = next_page.a[\"href\"]  # Extract next page link\n",
    "            page_url = base_url + next_page_url  # Update URL for next iteration\n",
    "        else:\n",
    "            break  # Exit loop if no \"Next\" button found\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page. Status Code: {response.status_code}\")\n",
    "        break  # Stop scraping if request fails\n",
    "\n",
    "# Convert list to DataFrame\n",
    "df = pd.DataFrame(book_data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"books_scraped.csv\", index=False)\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d5c768-976d-4656-a6f9-05996ff76a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
